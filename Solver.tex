\section{Iterative direction-dependent solver}
\label{sec:Solver}

\subsection{Linear system for calibration}


We find
the remarquable property that around the solution, Eq. \ref{eq:ME}
behaves like a linear system. Specifically, from Eq. \ref{eq:Jpq0} and
\ref{eq:Jpq1}, it is easy to check that:

%% \begin{alignat}{2}
%% \label{eq:Lin}
%% \vis=&\frac{1}{2}\JV\ \gwirt\\
%% \label{eq:Lin2}
%% =&\JVg\ \g=\JVCg\ \conj{\g}
%% \end{alignat}

\begin{alignat}{2}
\label{eq:Lin}
\vis=&\frac{1}{2}\left(\JV\big|_{\gwirt}\right)\ \gwirt\\
\label{eq:Lin2}
=&\left(\JVg\big|_{\conj{\g}}\right)\ \g=\left(\JVCg\big|_{\g}\right)\ \conj{\g}
\end{alignat}

%% \begin{alignat}{2}
%% \label{eq:Lin}
%% \mathbf{v}=\left(\JV\big|_{\vec{g}}\right).\vec{g}
%% \end{alignat}

%% \noindent where $\JV\big|_{\vec{g}}$ mean that the Jacobian is
%% evaluated at $\vec{g}$.

Both Eq. \ref{eq:Lin} and \ref{eq:Lin2} form linear systems.

\separator

Assuming a linear operator satisfying
Eq. \ref{eq:Lin} is given, we can build an iterative scheme to
derive an estimate $\widehat{\vec{g}}$ of $\vec{g}$. The linear operator
$\JVg$ is build from the estimate
$\widehat{\vec{g}_i}$ at step $i$. Then Eq. \ref{eq:Lin} is solved
using the least-squares solution given by computing pseudo-inverse as follows:

\def\A{\textbf{A}}

\begin{alignat}{2}
\label{eq:Solve}
\widehat{\vec{g}_{i+1}}=&\left[\A^H\textbf{C}^{-1}\A\right]^{-1}\A^H\textbf{C}^{-1}\mathbf{v}\\
\label{eq:SolveA}
\text{with } \A=&\JVg\big|_{\conj{\widehat{\g_i}}}
\end{alignat}

\noindent where \textbf{C} is the covariance matrix of $\mathbf{v}$.


\subsection{Convergence and averaging}

As shown in Fig. ... the convergence of this algorithm is slow, and
following Stef-the-great, instead of estimating $\JV$ at
$\widehat{\vec{g}_i}$, we build it at a modified location constructed
from previous iterations, and Eq. \ref{eq:SolveA} becomes:

\begin{alignat}{2}
\A=&\JV\big|_{\widetilde{\vec{g}_i}}\\
\text{with } \widetilde{\vec{g}_i}=&(\widehat{\vec{g}_{i-1}}+\widehat{\vec{g}_{i}})/2
\end{alignat}


